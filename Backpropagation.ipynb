{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Backpropagation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hinsley/colabs/blob/master/Backpropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR12WaNxULg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA0XzPsoUZCm",
        "colab_type": "code",
        "outputId": "2cea1e89-98a7-46f1-ce17-7ebefd22d402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "# Bias weights are always zero-indexed in each node's array. Bias weight is not\n",
        "# counted into layer sizes.\n",
        "\n",
        "input_size = 5\n",
        "\n",
        "layer_sizes = [5, 10, 3]\n",
        "\n",
        "nn_list = [[[]] * input_size] # A bit wasteful computationally, but helps keep\n",
        "                              # the initialization algorithm concise.\n",
        "for layer_size in layer_sizes:\n",
        "  # Note that each node has an additional weight initialized for its bias.\n",
        "  nn_list.append([np.random.random(len(nn_list[-1]) + 1) for\n",
        "                  node in\n",
        "                  range(layer_size)])\n",
        "\n",
        "del nn_list[0]\n",
        "\n",
        "nn_list"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[array([0.5488135 , 0.71518937, 0.60276338, 0.54488318, 0.4236548 ,\n",
              "         0.64589411]),\n",
              "  array([0.43758721, 0.891773  , 0.96366276, 0.38344152, 0.79172504,\n",
              "         0.52889492]),\n",
              "  array([0.56804456, 0.92559664, 0.07103606, 0.0871293 , 0.0202184 ,\n",
              "         0.83261985]),\n",
              "  array([0.77815675, 0.87001215, 0.97861834, 0.79915856, 0.46147936,\n",
              "         0.78052918]),\n",
              "  array([0.11827443, 0.63992102, 0.14335329, 0.94466892, 0.52184832,\n",
              "         0.41466194])],\n",
              " [array([0.26455561, 0.77423369, 0.45615033, 0.56843395, 0.0187898 ,\n",
              "         0.6176355 ]),\n",
              "  array([0.61209572, 0.616934  , 0.94374808, 0.6818203 , 0.3595079 ,\n",
              "         0.43703195]),\n",
              "  array([0.6976312 , 0.06022547, 0.66676672, 0.67063787, 0.21038256,\n",
              "         0.1289263 ]),\n",
              "  array([0.31542835, 0.36371077, 0.57019677, 0.43860151, 0.98837384,\n",
              "         0.10204481]),\n",
              "  array([0.20887676, 0.16130952, 0.65310833, 0.2532916 , 0.46631077,\n",
              "         0.24442559]),\n",
              "  array([0.15896958, 0.11037514, 0.65632959, 0.13818295, 0.19658236,\n",
              "         0.36872517]),\n",
              "  array([0.82099323, 0.09710128, 0.83794491, 0.09609841, 0.97645947,\n",
              "         0.4686512 ]),\n",
              "  array([0.97676109, 0.60484552, 0.73926358, 0.03918779, 0.28280696,\n",
              "         0.12019656]),\n",
              "  array([0.2961402 , 0.11872772, 0.31798318, 0.41426299, 0.0641475 ,\n",
              "         0.69247212]),\n",
              "  array([0.56660145, 0.26538949, 0.52324805, 0.09394051, 0.5759465 ,\n",
              "         0.9292962 ])],\n",
              " [array([0.31856895, 0.66741038, 0.13179786, 0.7163272 , 0.28940609,\n",
              "         0.18319136, 0.58651293, 0.02010755, 0.82894003, 0.00469548,\n",
              "         0.67781654]),\n",
              "  array([0.27000797, 0.73519402, 0.96218855, 0.24875314, 0.57615733,\n",
              "         0.59204193, 0.57225191, 0.22308163, 0.95274901, 0.44712538,\n",
              "         0.84640867]),\n",
              "  array([0.69947928, 0.29743695, 0.81379782, 0.39650574, 0.8811032 ,\n",
              "         0.58127287, 0.88173536, 0.69253159, 0.72525428, 0.50132438,\n",
              "         0.95608363])]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jnlLSnBVch6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feed_forward(network, inputs):\n",
        "  \"\"\"\n",
        "  Here we use a typical densely-connected set of layers. I forget the term for\n",
        "  this.\n",
        "  \"\"\"\n",
        "\n",
        "  bias = 1.0\n",
        "\n",
        "  def activation(input_):\n",
        "    # We use ReLU here. I'm too lazy to come up with names that avoid keyword\n",
        "    # conflicts.\n",
        "    return 0 if input_ < 0 else input_\n",
        "\n",
        "  def propagate(weight_matrix, inputs):\n",
        "    \"\"\"\n",
        "    Perform matrix multiplication of weight matrix with inputs. Columns in\n",
        "    weight_matrix and rows in inputs should be equal. We then run each result\n",
        "    in the \"potentials\" vector through an activation function, finishing by\n",
        "    prepending a constant bias term to the result vector.\n",
        "\n",
        "    Note that this function assumes a bias has already been added to inputs,\n",
        "    and is not able to discern whether its output should be the true output\n",
        "    of the network (you will have to manually prune the bias term from the\n",
        "    return value with `propagate(...)[1:]` or equivalent on the output layer).\n",
        "\n",
        "    I know this docstring is kind of long for what this function actually\n",
        "    accomplishes, but if you're a programmer and you can't be bothered to spend\n",
        "    a minute reading from time to time then I've got bad news for you.\n",
        "\n",
        "    Twas bryllyg, and the slythy toves\n",
        "    Did gyre and gymble in the wabe:\n",
        "    All mimsy were the borogoves;\n",
        "    And the mome raths outgrabe.\n",
        "\n",
        "    Jupyter desperately needs a block collapse feature.\n",
        "    \"\"\"\n",
        "\n",
        "    potentials = np.matmul(weight_matrix, inputs)\n",
        "    post_activation = [activation(potential) for potential in potentials]\n",
        "    \n",
        "    return np.concatenate(([bias], post_activation))\n",
        "\n",
        "  current_values = np.concatenate(([bias], inputs))\n",
        "\n",
        "  for layer in network:\n",
        "    current_values = propagate(layer, current_values)\n",
        "  \n",
        "  return current_values[1:] # Remove bias from output."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IwC2aIWr5-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aebeb71e-9357-46c4-9ee7-73602ad9c7ad"
      },
      "source": [
        "inputs = np.random.random(input_size)\n",
        "\n",
        "outputs = feed_forward(nn_list, inputs)\n",
        "\n",
        "outputs"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([17.29065649, 27.35296662, 30.39293233])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYgvTtWBpsdM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e96a092-4725-40e3-8e37-051c3ff7039b"
      },
      "source": [
        "def error(outputs, ideals):\n",
        "  \"\"\"We use root mean square error (RMSE) here.\"\"\"\n",
        "  return np.sum((ideals - outputs) ** 2) / outputs.size ** 0.5\n",
        "\n",
        "ideals = np.array([0.5, 0.75, 0.825]) # I totally made this up.\n",
        "\n",
        "error(outputs, ideals)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1076.1269774708546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wegBKOEdsnDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now I've just got to implement the actual backprop algorithm, and some kind of\n",
        "# batching procedure with test data. I'll do that whenever I get bored again.\n",
        "# It's midnight."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}